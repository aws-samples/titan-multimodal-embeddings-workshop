{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f71044d-9d3f-4c07-a5ad-94cef12aa695",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Multimodal Workshop\n",
    "## Multimodal Embeddings Model Customization\n",
    "This notebook is an end-to-end example of finetuning an Amazon Titan Multimodal Embeddings model which adapts the model to your domain. \n",
    "\n",
    "In this case we are going to train an embeddings model with sign language images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a186db8-8057-4404-b34d-6ad7e36632be",
   "metadata": {},
   "source": [
    "## 1. Import needed libraries\n",
    "Let's begin by importing all the libraries and initializing all the clients needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17132c03-f084-4469-ab9a-b7f0ab2693da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install opensearch-py requests_aws4auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f029bf1a-f95e-456f-9a14-3815ef6dd69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sts::947565228676:assumed-role/SageMakerRole/SageMaker\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "import shutil\n",
    "import random\n",
    "import logging\n",
    "import datetime\n",
    "from PIL import Image\n",
    "import concurrent.futures\n",
    "from utils import resize_image\n",
    "from ipywidgets import Dropdown\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from aoss_utils import createEncryptionPolicy, createNetworkPolicy, createAccessPolicy, createCollection, waitForCollectionCreation\n",
    "\n",
    "# Boto3 clients\n",
    "s3_client = boto3.client('s3')\n",
    "iam_client = boto3.client('iam')\n",
    "sts_client = boto3.client('sts')\n",
    "bedrock_client = boto3.client('bedrock')\n",
    "opensearch_client = boto3.client('opensearchserverless')\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")\n",
    "\n",
    "# Account and region info\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "identity_arn = session.client('sts').get_caller_identity()['Arn']\n",
    "print(identity_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61feb87-9251-4754-a573-4d481fd97790",
   "metadata": {},
   "source": [
    "## 2. Dataset preparation\n",
    "\n",
    "For the training dataset, create a .jsonl file with multiple JSON lines. Each JSON line contains both an image-ref and caption attributes similar to Sagemaker Augmented Manifest format. A validation dataset is required. Auto-captioning is not currently supported.\n",
    "\n",
    "```\n",
    "   {\"image-ref\": \"s3://bucket-1/folder1/0001.png\", \"caption\": \"some text\"}\n",
    "   {\"image-ref\": \"s3://bucket-1/folder1/0002.png\", \"caption\": \"some text\"}\n",
    "   {\"image-ref\": \"s3://bucket-1/folder1/0003.png\", \"caption\": \"some text\"}\n",
    "```  \n",
    "\n",
    "The Amazon S3 paths need to be in the same folders where you have provided permissions for Amazon Bedrock to access the data by attaching an IAM policy to your Amazon Bedrock service role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6986955-94ef-4646-8de7-b327f38d2cd6",
   "metadata": {},
   "source": [
    "### 2.1 Create an Amazon S3 bucket\n",
    "Create an bucket where your input/output data will be stored.\n",
    "\n",
    "If you already have a bucket created, replace the name in the next cell and skip the following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fef9bc3-02a6-431c-91b7-9d0050e86293",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket_name = \"amazonbr-fine-tune-embeddings-{}-{}\".format(account_id, region)\n",
    "s3_bucket_path = \"s3://{}\".format(s3_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "727e7820-1e1d-4e03-922a-66438a8254a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Bucket: amazonbr-fine-tune-embeddings-947565228676-us-east-1\n",
      "S3 bucket path: s3://amazonbr-fine-tune-embeddings-947565228676-us-east-1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if region != 'us-east-1':\n",
    "        s3_client.create_bucket(\n",
    "            Bucket=s3_bucket_name,     \n",
    "            CreateBucketConfiguration={\n",
    "                'LocationConstraint': region\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        s3_client.create_bucket(Bucket=s3_bucket_name)\n",
    "    print(\"AWS Bucket: {}\".format(s3_bucket_name))\n",
    "except Exception as err:\n",
    "    print(\"ERROR: {}\".format(err))\n",
    "\n",
    "s3_bucket_path = \"s3://{}\".format(s3_bucket_name)\n",
    "print(\"S3 bucket path: {}\".format(s3_bucket_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f764f-cda1-40f8-a084-576686dec908",
   "metadata": {},
   "source": [
    "### 2.2 Prepare the dataset\n",
    "In this section we will iterate over our training images to prepare the jsonl file with the images location and caption. \n",
    "\n",
    "The images will also be uploaded to Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce96b91-e43b-4b2c-90ae-e6a6f9165e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images_folder = 'training_images'\n",
    "validation_images_folder = 'validation_images'\n",
    "test_images_folder = 'test_images'\n",
    "training_output_file = 'training-output.jsonl'\n",
    "validation_output_file = 'validation-output.jsonl'\n",
    "s3_folder_training = 'hand-signs/training'\n",
    "s3_folder_validation = 'hand-signs/validation'\n",
    "json_objects = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8c973-4ff4-4ae8-a8f5-71b0bba06ce8",
   "metadata": {},
   "source": [
    "### Prepare the dataset\n",
    "Let's begin downloading the dataset and dividing it in training and validation folders\n",
    "\n",
    "The dataset we will be using is the [American Sign Language Letters](https://public.roboflow.com/object-detection/american-sign-language-letters?ref=blog.roboflow.com) by David Lee.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bcc3aad-74ad-426a-919f-3e58cd14d58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   901  100   901    0     0   3142      0 --:--:-- --:--:-- --:--:--  3150\n",
      "100 21.9M  100 21.9M    0     0  24.1M      0 --:--:-- --:--:-- --:--:-- 63.7M\n"
     ]
    }
   ],
   "source": [
    "!mkdir dataset\n",
    "!curl -L \"https://public.roboflow.com/ds/yGoz92zYzk?key=cNAlYH46dk\" > dataset/roboflow.zip;\n",
    "!unzip -q dataset/roboflow.zip; \n",
    "!rm README.roboflow.txt\n",
    "!rm README.dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "521dd136-74a7-469e-a3c1-f1239d7766d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir_1 = \"train\"\n",
    "parent_dir_2 = \"valid\"\n",
    "if not os.path.exists(training_images_folder):\n",
    "    os.makedirs(training_images_folder)\n",
    "if not os.path.exists(validation_images_folder):\n",
    "    os.makedirs(validation_images_folder)\n",
    "if not os.path.exists(test_images_folder):\n",
    "    os.makedirs(test_images_folder)\n",
    "\n",
    "\n",
    "# Function to handle duplicate filenames\n",
    "def get_unique_filename(dest_dir, filename):\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    counter = 1\n",
    "    new_name = name + ext\n",
    "    while os.path.exists(os.path.join(dest_dir, new_name)):\n",
    "        new_name = f\"{name}_{counter}{ext}\"\n",
    "        counter += 1\n",
    "    return new_name\n",
    "\n",
    "# Iterate over the parent directories\n",
    "for parent_dir in [parent_dir_1, parent_dir_2]:\n",
    "    for letter_dir in os.listdir(parent_dir):\n",
    "        letter_path = os.path.join(parent_dir, letter_dir)\n",
    "        if os.path.isdir(letter_path):\n",
    "            # Get a list of files in the subfolder\n",
    "            files = [f for f in os.listdir(letter_path) if os.path.isfile(os.path.join(letter_path, f))]\n",
    "\n",
    "            # Shuffle the list of files randomly\n",
    "            random.shuffle(files)\n",
    "\n",
    "            # Calculate the split index for 80/20 split\n",
    "            split_index = int(0.8 * len(files))\n",
    "\n",
    "            # Iterate over the files and move them to the appropriate destination\n",
    "            for i, filename in enumerate(files):\n",
    "                src_file = os.path.join(letter_path, filename)\n",
    "                name_parts = filename.split(\"_\")\n",
    "                new_name = name_parts[0] + os.path.splitext(filename)[1]\n",
    "\n",
    "                if i < split_index:\n",
    "                    # Move to training_images\n",
    "                    dest_dir = training_images_folder\n",
    "                else:\n",
    "                    # Move to validation_images\n",
    "                    dest_dir = validation_images_folder\n",
    "\n",
    "                # Handle duplicate filenames\n",
    "                new_name = get_unique_filename(dest_dir, new_name)\n",
    "                dest_file = os.path.join(dest_dir, new_name)\n",
    "                shutil.move(src_file, dest_file)\n",
    "\n",
    "# Set the directory paths\n",
    "src_dir = \"test\"\n",
    "dst_dir = \"test_images\"\n",
    "\n",
    "# Loop through each subfolder in the source directory\n",
    "for subfolder in os.listdir(src_dir):\n",
    "    subfolder_path = os.path.join(src_dir, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Loop through each file in the subfolder\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            file_path = os.path.join(subfolder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                # Split the filename by '_'\n",
    "                name_parts = os.path.splitext(filename)\n",
    "                # Get the part before '_' and the extension\n",
    "                new_name = name_parts[0].split('_')[0] + name_parts[1]\n",
    "                # Construct the new file path\n",
    "                new_file_path = os.path.join(dst_dir, new_name)\n",
    "                # Move the file to the destination directory with the new name\n",
    "                shutil.move(file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae985325-c375-4713-ad7b-af51a3617f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -R train/\n",
    "!rm -R valid/\n",
    "!rm -R test/\n",
    "!rm -R dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc3dc5-3202-4384-befd-c4eb1714df98",
   "metadata": {},
   "source": [
    "#### Upload dataset to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab2c2bb1-9b72-4609-b946-ae2c975a7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(s3_folder, image_folder, output_file):\n",
    "    json_objects = []\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "            # Construct the image reference\n",
    "            image_ref = os.path.join('s3://{}/{}'.format(s3_bucket_name, s3_folder), filename)\n",
    "            # Extract the first letter of the filename to create the caption\n",
    "            first_letter = filename[0]\n",
    "            caption = \"The letter {} in sign language\".format(first_letter)\n",
    "            # Create the JSON object\n",
    "            json_obj = {\"image-ref\": image_ref, \"caption\": caption}\n",
    "            # Append the JSON object to the list\n",
    "            json_objects.append(json_obj)\n",
    "            # Path to the current image file\n",
    "            file_path = os.path.join(image_folder, filename)\n",
    "            # Resize the image if it exceeds 2048x2048\n",
    "            resize_image(file_path)\n",
    "            # Upload the image to S3\n",
    "            s3_client.upload_file(file_path,\n",
    "                                  s3_bucket_name,\n",
    "                                  os.path.join(s3_folder, filename))\n",
    "\n",
    "    # Write the JSON objects to the output file in JSON Lines format\n",
    "    with open(output_file, 'w') as f:\n",
    "        for obj in json_objects:\n",
    "            f.write(json.dumps(obj) + '\\n')\n",
    "\n",
    "    print(\"Output file '{}' created successfully.\".format(output_file))\n",
    "    s3_client.upload_file(output_file, s3_bucket_name, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cd34f26-e909-428d-9dba-6784d74aba79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file 'training-output.jsonl' created successfully.\n"
     ]
    }
   ],
   "source": [
    "create_dataset(s3_folder_training, training_images_folder, training_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6463f545-6ac1-412c-bc6f-a9523e6a9ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file 'validation-output.jsonl' created successfully.\n"
     ]
    }
   ],
   "source": [
    "create_dataset(s3_folder_validation, validation_images_folder, validation_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3152d6-360d-42d4-b7af-4a296a85a992",
   "metadata": {},
   "source": [
    "## 3. Model fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27436f-805e-47ac-bf23-971d9849bb9e",
   "metadata": {},
   "source": [
    "### 3.1 Fine tune job preparation - Creating role and policies requirements\n",
    "\n",
    "We will now prepare the necessary role for the fine-tune job. That includes creating the policies required to run customization jobs with Amazon Bedrock.\n",
    "\n",
    "#### Create Trust relationship\n",
    "This JSON object defines the trust relationship that allows the bedrock service to assume a role that will give it the ability to talk to other required AWS services. The conditions set restrict the assumption of the role to a specfic account ID and a specific component of the bedrock service (model_customization_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb44f05-33c7-4926-8197-a8e2bb5b2bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = \"AmazonBedrockFineTuning-Multimodal-Embeddings-test\"\n",
    "s3_bedrock_ft_access_policy=\"AmazonBedrockFT-Multimodal-S3-test\"\n",
    "customization_role = f\"arn:aws:iam::{account_id}:role/{role_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc36fc0-f150-4a33-9386-48d026dfe997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This JSON object defines the trust relationship that allows the bedrock service to assume a role that will give it the ability to talk to other required AWS services. The conditions set restrict the assumption of the role to a specfic account ID and a specific component of the bedrock service (model_customization_jobs)\n",
    "ROLE_DOC = f\"\"\"{{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {{\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {{\n",
    "                \"Service\": \"bedrock.amazonaws.com\"\n",
    "            }},\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "            \"Condition\": {{\n",
    "                \"StringEquals\": {{\n",
    "                    \"aws:SourceAccount\": \"{account_id}\"\n",
    "                }},\n",
    "                \"ArnEquals\": {{\n",
    "                    \"aws:SourceArn\": \"arn:aws:bedrock:{region}:{account_id}:model-customization-job/*\"\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e3b14-7e48-4f1e-a5d2-3a9209775e96",
   "metadata": {},
   "source": [
    "#### Create S3 access policy\n",
    "\n",
    "This JSON object defines the permissions of the role we want bedrock to assume to allow access to the S3 bucket that we created that will hold our fine-tuning datasets and allow certain bucket and object manipulations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06778024-93a9-4e3f-8766-eb62146f9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_POLICY_DOC = f\"\"\"{{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {{\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:AbortMultipartUpload\",\n",
    "                \"s3:DeleteObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:GetBucketAcl\",\n",
    "                \"s3:GetBucketNotification\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:PutBucketNotification\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{s3_bucket_name}\",\n",
    "                \"arn:aws:s3:::{s3_bucket_name}/*\"\n",
    "            ]\n",
    "        }}\n",
    "    ]\n",
    "}}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f1982c-2dbc-4b78-90ab-625603e3a684",
   "metadata": {},
   "source": [
    "#### Create IAM role and attach policies\n",
    "\n",
    "Let's now create the IAM role with the created trust policy and attach the s3 policy to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17b067-649b-40ac-ae3d-2c1d197a9ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = iam_client.create_role(\n",
    "    RoleName=role_name,\n",
    "    AssumeRolePolicyDocument=ROLE_DOC,\n",
    "    Description=\"Role for Bedrock to access S3 for finetuning\",\n",
    ")\n",
    "\n",
    "role_arn = response[\"Role\"][\"Arn\"]\n",
    "response = iam_client.create_policy(\n",
    "    PolicyName=s3_bedrock_ft_access_policy,\n",
    "    PolicyDocument=ACCESS_POLICY_DOC,\n",
    ")\n",
    "policy_arn = response[\"Policy\"][\"Arn\"]\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyArn=policy_arn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a7f4f-91d4-4743-adba-fd22e04fcb11",
   "metadata": {},
   "source": [
    "### 3.2 Create Fine-tuning job\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> Fine-tuning job will take around 1 hours to complete.\n",
    "</div>\n",
    "\n",
    "Now that we have all the requirements in place, let's create the fine-tuning job with the Titan Multimodal Embeddings model.\n",
    "\n",
    "To do so, we need to set the model **hyperparameters** for `epoochsCount`, `batchSize` and `learningRate` and provide the path to your training and validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0774d-c5bb-4227-b784-88d5872d76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "base_model_id = \"amazon.titan-embed-image-v1:0\"\n",
    "customization_type = \"FINE_TUNING\"\n",
    "customization_role = role_arn\n",
    "customization_job_name = f\"image-emb-ft-{ts}\"\n",
    "custom_model_name = f\"image-emb-ft-{ts}\"\n",
    "hyper_parameters = {\n",
    "    \"epochCount\": \"auto\",\n",
    "    \"batchSize\": \"256\",\n",
    "    \"learningRate\": \"0.00001\",\n",
    "}\n",
    "s3_train_uri = s3_bucket_path + \"/\" + training_output_file\n",
    "s3_validation_uri = s3_bucket_path + \"/\" + validation_output_file\n",
    "training_data_config = {\"s3Uri\": s3_train_uri}\n",
    "validation_data_config = {\n",
    "        'validators': [\n",
    "            {\n",
    "                's3Uri': s3_validation_uri\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "\n",
    "output_data_config = {\"s3Uri\": f's3://{s3_bucket_name}/outputs/output-{custom_model_name}'}\n",
    "\n",
    "# Create the customization job\n",
    "bedrock_client.create_model_customization_job(\n",
    "    customizationType=customization_type,\n",
    "    jobName=customization_job_name,\n",
    "    customModelName=custom_model_name,\n",
    "    roleArn=customization_role,\n",
    "    baseModelIdentifier=base_model_id,\n",
    "    hyperParameters=hyper_parameters,\n",
    "    trainingDataConfig=training_data_config,\n",
    "    validationDataConfig=validation_data_config,\n",
    "    outputDataConfig=output_data_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f716e681-0a95-4b41-b421-030e726fba36",
   "metadata": {},
   "source": [
    "#### Waiting until customization job is completed\n",
    "Once the customization job is finished, you can check your existing custom model(s) and retrieve the modelArn of your fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889fdc4-1957-456a-9f38-78fca9ca6c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = bedrock_client.list_model_customization_jobs(\n",
    "    nameContains=customization_job_name\n",
    ")[\"modelCustomizationJobSummaries\"][0][\"status\"]\n",
    "while status == 'InProgress':\n",
    "    time.sleep(50)\n",
    "    status = bedrock_client.list_model_customization_jobs(\n",
    "        nameContains=customization_job_name\n",
    "    )[\"modelCustomizationJobSummaries\"][0][\"status\"]\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd97c41-8cff-4b1b-a603-e9e7df568a80",
   "metadata": {},
   "source": [
    "### 3.3 Provision the fine-tuned model\n",
    "You can use the fine-tuned model by purchasing provisioning or with Amazon Bedrock Batch Inference. In this notebook we will provision the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9de21fa-fd6b-47b1-a8a1-cb5393cc6e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727cee3f6cc44b339f5d64ba3925e80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select a model', layout=Layout(width='max-content'), options=('image-emb-ft-2024-03-26-0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "customization_jobs = {}\n",
    "dropdown_vals = []\n",
    "for cj in bedrock_client.list_model_customization_jobs()[\"modelCustomizationJobSummaries\"]:\n",
    "    if cj[\"status\"] == \"Completed\":\n",
    "        customization_jobs[cj[\"customModelName\"]] = cj\n",
    "        dropdown_vals.append(cj[\"customModelName\"] + \" - creationTime: \" + cj[\"creationTime\"].strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# display the model-ids in a dropdown to select a model for inference.\n",
    "model_dropdown = Dropdown(\n",
    "    options=dropdown_vals,\n",
    "    value=dropdown_vals[0],\n",
    "    description=\"Select a model\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")\n",
    "display(model_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f98be028-8a0e-4fb7-aecd-9249bb6ae97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('image-emb-ft-2024-03-26-09-58-05',\n",
       " 'arn:aws:bedrock:us-east-1:947565228676:custom-model/amazon.titan-embed-image-v1:0/wrmjvnf7a922')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_model = model_dropdown.value.split(\" - creationTime: \")[0]\n",
    "custom_model_name, custom_model_arn = selected_model, customization_jobs[selected_model][\"customModelArn\"]\n",
    "custom_model_name, custom_model_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fc77cc-6628-41d3-83d8-711a190530fe",
   "metadata": {},
   "source": [
    "\n",
    "#### Create Provisioned Model Throughput\n",
    "**Note:** Creating provisioned throughput will take around 10 mins to complete.\n",
    "\n",
    "You will need to create provisioned throughput to be able to evaluate the model performance. You can do so through the console or use the following api call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "033a695d-060d-4fd0-9ed9-ae315a9495ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the provision throughput job and retrieve the provisioned model id\n",
    "provisioned_model_id = bedrock_client.create_provisioned_model_throughput(\n",
    "    modelUnits=1,\n",
    "    # create a name for your provisioned throughput model\n",
    "    provisionedModelName=custom_model_name,\n",
    "    modelId=custom_model_arn\n",
    ")['provisionedModelArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca01be5d-3629-447c-a790-f9045e9d6cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n",
      "CPU times: user 67.4 ms, sys: 16.1 ms, total: 83.5 ms\n",
      "Wall time: 11min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# check provisioned throughput job status\n",
    "import time\n",
    "status_provisioning = bedrock_client.get_provisioned_model_throughput(provisionedModelId = provisioned_model_id)['status'] \n",
    "while status_provisioning == 'Creating':\n",
    "    time.sleep(60)\n",
    "    status_provisioning = bedrock_client.get_provisioned_model_throughput(provisionedModelId=provisioned_model_id)['status']\n",
    "    print(status_provisioning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4e46f-ae2e-43fb-a581-9f7a31f6ea2a",
   "metadata": {},
   "source": [
    "## 4. Create two indexes with the base and finetuned models embeddings\n",
    "Now we have fine-tuned our model, we are going to test it against the base model. To achieve this, we will create two Amazon Opensearch Serverless indexes and populate them with hand sign language image embeddings, each one using its respective embeddings model. The we will query the index to retrieve images related to alphabet letters in hand sign language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5310ec-5b55-4cb5-9b4d-fb59ed043918",
   "metadata": {},
   "source": [
    "### Create the vector indexes using Amazon OpenSearch Serverless\n",
    "\n",
    "#### Create an Amazon OpenSearch Serverless Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15ee746e-2df2-421b-b691-34325044c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('opensearchserverless')\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, \"aoss\", session_token=credentials.token)\n",
    "collection_name = \"sign-language-collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c67e7b7-bef7-4d39-9bc3-7f3179c529da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encryption policy created:\n",
      "{'securityPolicyDetail': {'createdDate': 1712314742191, 'description': 'Encryption policy for sign-language-collection collection', 'lastModifiedDate': 1712314742191, 'name': 'sign-language-collection-policy', 'policy': {'Rules': [{'Resource': ['collection/sign-language-collection*'], 'ResourceType': 'collection'}], 'AWSOwnedKey': True}, 'policyVersion': 'MTcxMjMxNDc0MjE5MV8x', 'type': 'encryption'}, 'ResponseMetadata': {'RequestId': '33f2bc35-f678-4d22-88c4-a7aa34e439cf', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '33f2bc35-f678-4d22-88c4-a7aa34e439cf', 'date': 'Fri, 05 Apr 2024 10:59:02 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '383', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "\n",
      "Network policy created:\n",
      "{'securityPolicyDetail': {'createdDate': 1712314742289, 'description': 'Network policy for sign-language-collection collection', 'lastModifiedDate': 1712314742289, 'name': 'sign-language-collection-policy', 'policy': [{'Rules': [{'Resource': ['collection/sign-language-collection*'], 'ResourceType': 'dashboard'}, {'Resource': ['collection/sign-language-collection*'], 'ResourceType': 'collection'}], 'AllowFromPublic': True, 'Description': 'Public access for sign-language-collection collection'}], 'policyVersion': 'MTcxMjMxNDc0MjI4OV8x', 'type': 'network'}, 'ResponseMetadata': {'RequestId': '5ac1100c-aeaa-4852-b3ac-18a7f9847e3d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '5ac1100c-aeaa-4852-b3ac-18a7f9847e3d', 'date': 'Fri, 05 Apr 2024 10:59:02 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '534', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "\n",
      "Access policy created:\n",
      "{'accessPolicyDetail': {'createdDate': 1712314742366, 'description': 'Data access policy for sign-language-collection collection', 'lastModifiedDate': 1712314742366, 'name': 'sign-language-collection-policy', 'policy': [{'Rules': [{'Resource': ['index/sign-language-collection*/*'], 'Permission': ['aoss:CreateIndex', 'aoss:DeleteIndex', 'aoss:UpdateIndex', 'aoss:DescribeIndex', 'aoss:ReadDocument', 'aoss:WriteDocument'], 'ResourceType': 'index'}, {'Resource': ['collection/sign-language-collection*'], 'Permission': ['aoss:CreateCollectionItems'], 'ResourceType': 'collection'}], 'Principal': ['arn:aws:sts::947565228676:assumed-role/SageMakerRole/SageMaker']}], 'policyVersion': 'MTcxMjMxNDc0MjM2Nl8x', 'type': 'data'}, 'ResponseMetadata': {'RequestId': '2090a0eb-caf7-4dee-83ea-c98a0cd81f79', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '2090a0eb-caf7-4dee-83ea-c98a0cd81f79', 'date': 'Fri, 05 Apr 2024 10:59:02 GMT', 'content-type': 'application/x-amz-json-1.0', 'content-length': '690', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n",
      "Creating collection...\n",
      "\n",
      "Collection successfully created:\n",
      "[{'arn': 'arn:aws:aoss:us-east-1:947565228676:collection/2pfquksf2w8l8t7cffjc', 'collectionEndpoint': 'https://2pfquksf2w8l8t7cffjc.us-east-1.aoss.amazonaws.com', 'createdDate': 1712314742454, 'dashboardEndpoint': 'https://2pfquksf2w8l8t7cffjc.us-east-1.aoss.amazonaws.com/_dashboards', 'id': '2pfquksf2w8l8t7cffjc', 'kmsKeyArn': 'auto', 'lastModifiedDate': 1712314766368, 'name': 'sign-language-collection', 'status': 'ACTIVE', 'type': 'VECTORSEARCH'}]\n"
     ]
    }
   ],
   "source": [
    "createEncryptionPolicy(client, collection_name)\n",
    "createNetworkPolicy(client, collection_name)\n",
    "createAccessPolicy(client, collection_name, identity_arn)\n",
    "createCollection(client, collection_name)\n",
    "hostname, collection_id = waitForCollectionCreation(client, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73564954-2e53-408e-803b-9b86ba8d796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, \"aoss\", session_token=credentials.token)\n",
    "OSSclient = OpenSearch(\n",
    "    hosts=[{'host': hostname, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=900\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfb1ff5-bda5-4ae2-8cfd-788bfa22e93d",
   "metadata": {},
   "source": [
    "#### Create the vector indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b33e30-4477-4fa2-b14a-86f225d1deb4",
   "metadata": {},
   "source": [
    "Before creating the indexes you will need to define the output vector size for Amazon Titan Multimodal Embeddings.\n",
    "\n",
    "Available sizes – 1,024 (default), 384, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0932885a-907f-4530-aa2e-2106c39457c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputEmbeddingLength = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e6b11c0-2e7e-472e-b181-98cf824d93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(index, outputEmbeddingLength):\n",
    "    if not OSSclient.indices.exists(index):\n",
    "        settings = {\n",
    "            \"settings\": {\n",
    "                \"index\": {\n",
    "                    \"knn\": True,\n",
    "                }\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"letter\": {\"type\": \"text\"},\n",
    "                    \"description\": {\"type\": \"text\"},\n",
    "                    \"createtime\": {\"type\": \"text\"},\n",
    "                    \"image_path\":{\"type\": \"text\"},\n",
    "                    \"vector_field\": {\n",
    "                        \"type\": \"knn_vector\",\n",
    "                        \"dimension\": outputEmbeddingLength,\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "        res = OSSclient.indices.create(index, body=settings)\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69d4c11b-687e-4927-8550-87683c0ddb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_index_name = \"sign-language-collection-base-{}\".format(outputEmbeddingLength)\n",
    "finetuned_index_name = \"sign-language-collection-finetuned-{}\".format(outputEmbeddingLength)\n",
    "base_modelId = \"amazon.titan-embed-image-v1\"\n",
    "finetuned_modelId = provisioned_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b7f2c30-ad51-4b92-97e4-9c96f590e309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'sign-language-collection-finetuned-1024'}\n"
     ]
    }
   ],
   "source": [
    "create_index(base_index_name, outputEmbeddingLength)\n",
    "create_index(finetuned_index_name, outputEmbeddingLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797b0fb-28ae-4d64-b4c7-861c2214532f",
   "metadata": {},
   "source": [
    "### Populate the vector indexes\n",
    "Let's populate both indexes with our test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "698266bc-e7cb-4316-b85e-e1c9fc7d137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_of_image(image, modelId, outputEmbeddingLength = outputEmbeddingLength):\n",
    "    with open(image, \"rb\") as image_file:\n",
    "        imageEncoded = base64.b64encode(image_file.read()).decode('utf8')\n",
    "\n",
    "    body = json.dumps(\n",
    "    {\n",
    "            \"inputImage\": imageEncoded,\n",
    "            #\"inputText\":text,\n",
    "            \"embeddingConfig\": { \n",
    "                \"outputEmbeddingLength\": outputEmbeddingLength\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=body, \n",
    "        modelId=modelId, \n",
    "        accept=\"application/json\", \n",
    "        contentType=\"application/json\"       \n",
    "    )\n",
    "\n",
    "    vector = json.loads(response['body'].read().decode('utf8'))\n",
    "    return vector\n",
    "\n",
    "\n",
    "def create_dataset_list(folder_path):\n",
    "    dataset_list = []\n",
    "    \n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file is an image (you can modify the extension check as needed)\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            dataset_list.append(file_path)\n",
    "    \n",
    "    return dataset_list\n",
    "    \n",
    "def process_batch(batch, index, modelId, outputEmbeddingLength):\n",
    "    start_time = datetime.datetime.now()\n",
    "    bulk_data = \"\"\n",
    "    for entry in batch:        \n",
    "        letter = entry.split('/')[-1][0]\n",
    "        text = \"The letter {} in sign language\".format(letter)\n",
    "        vector = get_embeddings_of_image(entry, modelId, outputEmbeddingLength)\n",
    "        dt = datetime.datetime.now().isoformat()\n",
    "        doc = {\n",
    "            \"vector_field\" : vector[\"embedding\"],\n",
    "            \"createtime\": dt,\n",
    "            \"letter\": letter,\n",
    "            \"description\": text,\n",
    "            \"image_path\": entry\n",
    "        }\n",
    "        bulk_entry = \"{{\\\"index\\\": {{\\\"_index\\\": \\\"{}\\\"}}}}\\n{}\\n\".format(index, json.dumps(doc))\n",
    "        bulk_data += bulk_entry\n",
    "    end_time = datetime.datetime.now()\n",
    "    processing_time = (end_time - start_time).total_seconds() * 1000  # Convert to milliseconds\n",
    "    print(\"Processed {} records in {} ms\".format(len(batch), processing_time))\n",
    "    response = OSSclient.bulk(bulk_data)\n",
    "    if (response[\"errors\"] is False):\n",
    "        print(\"Sent {} records in {} ms\".format(len(response[\"items\"]), response[\"took\"]))\n",
    "    else:\n",
    "        print(\"Error found\")\n",
    "\n",
    "\n",
    "def populate_vector_database(folder_path, index, modelId, outputEmbeddingLength, batch_size=25):\n",
    "    dataset_list = create_dataset_list(folder_path)\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Split the dataset into batches\n",
    "        batches = [dataset_list[i:i+batch_size] for i in range(0, len(dataset_list), batch_size)]\n",
    "\n",
    "        # Map the process_batch function to each batch in the dataset using multiple threads\n",
    "        futures = [executor.submit(process_batch, batch, index, modelId, outputEmbeddingLength) for batch in batches]\n",
    "\n",
    "        # Wait for all threads to complete\n",
    "        concurrent.futures.wait(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e75ada9-6344-47a4-88af-59758ae70e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 25 records in 3384.6099999999997 ms\n",
      "Processed 25 records in 3779.57 ms\n",
      "Sent 25 records in 459 ms\n",
      "Sent 25 records in 377 ms\n",
      "Processed 22 records in 4985.093 ms\n",
      "Sent 22 records in 307 ms\n"
     ]
    }
   ],
   "source": [
    "populate_vector_database(test_images_folder, base_index_name, base_modelId, outputEmbeddingLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c45df6a3-362f-45d8-9dd3-dd6406bd6fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 22 records in 6004.804 ms\n",
      "Sent 22 records in 294 ms\n",
      "Processed 25 records in 6815.2 ms\n",
      "Sent 25 records in 306 ms\n",
      "Processed 25 records in 7781.734 ms\n",
      "Sent 25 records in 303 ms\n"
     ]
    }
   ],
   "source": [
    "populate_vector_database(test_images_folder, finetuned_index_name, finetuned_modelId, outputEmbeddingLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f21f9-5249-472a-b759-921bef581e4c",
   "metadata": {},
   "source": [
    "Wait a couple of minutes for all the data to be accesible on Opensearch Serverless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d020bffe-1be1-4357-a964-a331898f40e0",
   "metadata": {},
   "source": [
    "## 5. Compare results\n",
    "Now we have populated both indexes, let's compare the query results using the base embeddings and fine-tuned embeddings.\n",
    "\n",
    "### Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03a94a5d-c3e5-4460-985c-0494bf335cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_for_text(text, modelId, outputEmbeddingLength):\n",
    "    body = json.dumps(\n",
    "        {\"inputText\": text, \n",
    "         \"embeddingConfig\": { \n",
    "                \"outputEmbeddingLength\": outputEmbeddingLength\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=body, \n",
    "        modelId=modelId, \n",
    "        accept=\"application/json\", \n",
    "        contentType=\"application/json\"       \n",
    "    )\n",
    "\n",
    "    vector_json = json.loads(response['body'].read().decode('utf8'))\n",
    "\n",
    "    return vector_json, text\n",
    "\n",
    "def query_the_database_with_text(text, index, modelId, outputEmbeddingLength, k):\n",
    "    o_vector_json, o_text = get_embedding_for_text(text, modelId, outputEmbeddingLength)\n",
    "    query = {\n",
    "      'query': {\n",
    "        'bool': {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"knn\":{\n",
    "                       'vector_field':{\n",
    "                           \"vector\":o_vector_json[\"embedding\"],\n",
    "                           \"k\": k\n",
    "                       } \n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    response = OSSclient.search(\n",
    "        body = query,\n",
    "        index = index\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c9b04d1-742b-4740-a1c7-e1b3452050d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The letter H in sign language'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_text_base = query_the_database_with_text(\"The letter B\", base_index_name, base_modelId,  outputEmbeddingLength, k=10)\n",
    "results_text_base[\"hits\"][\"hits\"][0][\"_source\"][\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee0be30b-7076-4844-bd9d-34c625f2d50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The letter B in sign language'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_text_finetuned = query_the_database_with_text(\"The letter B\", finetuned_index_name, finetuned_modelId, outputEmbeddingLength, k=10)\n",
    "results_text_finetuned[\"hits\"][\"hits\"][0][\"_source\"][\"description\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa206d6d-0848-49ad-83b9-97f19d91241b",
   "metadata": {},
   "source": [
    "#### Full comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba4a5b74-d163-4a9e-918f-a26f613686e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Letter                    Base Result              Fine-tuned Result\n",
      "0       A  The letter Q in sign language  The letter S in sign language\n",
      "1       B  The letter F in sign language  The letter B in sign language\n",
      "2       C  The letter F in sign language  The letter C in sign language\n",
      "3       D  The letter Q in sign language  The letter D in sign language\n",
      "4       E  The letter F in sign language  The letter N in sign language\n",
      "5       F  The letter F in sign language  The letter F in sign language\n",
      "6       G  The letter Q in sign language  The letter G in sign language\n",
      "7       H  The letter V in sign language  The letter H in sign language\n",
      "8       I  The letter V in sign language  The letter I in sign language\n",
      "9       J  The letter Q in sign language  The letter J in sign language\n",
      "10      K  The letter V in sign language  The letter K in sign language\n",
      "11      L  The letter Q in sign language  The letter Y in sign language\n",
      "12      M  The letter Q in sign language  The letter T in sign language\n",
      "13      N  The letter F in sign language  The letter M in sign language\n",
      "14      O  The letter F in sign language  The letter O in sign language\n",
      "15      P  The letter Q in sign language  The letter P in sign language\n",
      "16      Q  The letter F in sign language  The letter Q in sign language\n",
      "17      R  The letter V in sign language  The letter R in sign language\n",
      "18      S  The letter F in sign language  The letter S in sign language\n",
      "19      T  The letter F in sign language  The letter M in sign language\n",
      "20      U  The letter V in sign language  The letter U in sign language\n",
      "21      V  The letter V in sign language  The letter V in sign language\n",
      "22      W  The letter V in sign language  The letter W in sign language\n",
      "23      X  The letter V in sign language  The letter X in sign language\n",
      "24      Y  The letter V in sign language  The letter Y in sign language\n",
      "25      Z  The letter V in sign language  The letter Z in sign language\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_alphabet_results(base_index_name, base_modelId, finetuned_index_name, finetuned_modelId, outputEmbeddingLength):\n",
    "    alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    results = []\n",
    "\n",
    "    for letter in alphabet:\n",
    "        query = f\"The letter {letter} in sign language\"\n",
    "        results_text_base = query_the_database_with_text(query, base_index_name, base_modelId, outputEmbeddingLength, k=5)\n",
    "        base_description = results_text_base[\"hits\"][\"hits\"][0][\"_source\"][\"description\"]\n",
    "\n",
    "        results_text_finetuned = query_the_database_with_text(query, finetuned_index_name, finetuned_modelId, outputEmbeddingLength, k=5)\n",
    "        finetuned_description = results_text_finetuned[\"hits\"][\"hits\"][0][\"_source\"][\"description\"]\n",
    "\n",
    "        results.append({\n",
    "            'Letter': letter,\n",
    "            'Base Result': base_description,\n",
    "            'Fine-tuned Result': finetuned_description\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "# Call the function with your parameters\n",
    "df = compare_alphabet_results(base_index_name, base_modelId, finetuned_index_name, finetuned_modelId, outputEmbeddingLength)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9101306a-df48-425e-8bb9-c2ce6ad336e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model:\n",
      "Precision: 0.08\n",
      "\n",
      "Fine-tuned Model:\n",
      "Precision: 0.77\n"
     ]
    }
   ],
   "source": [
    "def calculate_precision(df):\n",
    "    base_tp = 0\n",
    "    base_fp = 0\n",
    "    base_fn = 0\n",
    "    finetuned_tp = 0\n",
    "    finetuned_fp = 0\n",
    "    finetuned_fn = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        letter = row['Letter']\n",
    "        base_result = row['Base Result']\n",
    "        finetuned_result = row['Fine-tuned Result']\n",
    "\n",
    "        expected_result = f\"The letter {letter} in sign language\"\n",
    "\n",
    "        if base_result == expected_result:\n",
    "            base_tp += 1\n",
    "        else:\n",
    "            base_fp += 1\n",
    "            base_fn += 1\n",
    "\n",
    "        if finetuned_result == expected_result:\n",
    "            finetuned_tp += 1\n",
    "        else:\n",
    "            finetuned_fp += 1\n",
    "            finetuned_fn += 1\n",
    "\n",
    "    base_precision = base_tp / (base_tp + base_fp) if (base_tp + base_fp) > 0 else 0\n",
    "    finetuned_precision = finetuned_tp / (finetuned_tp + finetuned_fp) if (finetuned_tp + finetuned_fp) > 0 else 0\n",
    "\n",
    "    return base_precision, finetuned_precision\n",
    "\n",
    "# Call the function with your DataFrame\n",
    "base_precision, finetuned_precision = calculate_precision(df)\n",
    "\n",
    "print(\"Base Model:\")\n",
    "print(f\"Precision: {base_precision:.2f}\")\n",
    "\n",
    "print(\"\\nFine-tuned Model:\")\n",
    "print(f\"Precision: {finetuned_precision:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8894c2-81b9-4942-9f15-d6735bdf97b6",
   "metadata": {},
   "source": [
    "## 6. Clean-up\n",
    "To avoid unnecessary costs, let's now delete the provisioned throughput model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55f862ac-c196-45eb-82b7-8e3150c0e954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 13:52:41,799 - INFO - Successfully deleted encryption security policy for sign-language-collection\n",
      "2024-04-05 13:52:41,885 - INFO - Successfully deleted network security policy for sign-language-collection\n",
      "2024-04-05 13:52:41,979 - INFO - Successfully deleted access policy for sign-language-collection\n",
      "2024-04-05 13:52:42,070 - INFO - Successfully deleted collection with ID 2pfquksf2w8l8t7cffjc\n",
      "2024-04-05 13:52:43,200 - INFO - Successfully deleted provisioned model throughput for ID arn:aws:bedrock:us-east-1:947565228676:provisioned-model/d41cl5bj2h4x\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def delete_security_policy(client, collection_name, policy_type):\n",
    "    try:\n",
    "        response = client.delete_security_policy(\n",
    "            name=f'{collection_name}-policy',\n",
    "            type=policy_type\n",
    "        )\n",
    "        logging.info(f'Successfully deleted {policy_type} security policy for {collection_name}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error deleting {policy_type} security policy for {collection_name}: {e}')\n",
    "\n",
    "def delete_access_policy(client, collection_name):\n",
    "    try:\n",
    "        response = client.delete_access_policy(\n",
    "            name=f'{collection_name}-policy',\n",
    "            type='data'\n",
    "        )\n",
    "        logging.info(f'Successfully deleted access policy for {collection_name}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error deleting access policy for {collection_name}: {e}')\n",
    "\n",
    "def delete_collection(client, collection_id):\n",
    "    try:\n",
    "        response = client.delete_collection(\n",
    "            id=collection_id\n",
    "        )\n",
    "        logging.info(f'Successfully deleted collection with ID {collection_id}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error deleting collection with ID {collection_id}: {e}')\n",
    "\n",
    "def delete_provisioned_model_throughput(bedrock_client, provisioned_model_id):\n",
    "    try:\n",
    "        response = bedrock_client.delete_provisioned_model_throughput(\n",
    "            provisionedModelId=provisioned_model_id\n",
    "        )\n",
    "        logging.info(f'Successfully deleted provisioned model throughput for ID {provisioned_model_id}')\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error deleting provisioned model throughput for ID {provisioned_model_id}: {e}')\n",
    "\n",
    "delete_security_policy(client, collection_name, 'encryption')\n",
    "delete_security_policy(client, collection_name, 'network')\n",
    "delete_access_policy(client, collection_name)\n",
    "delete_collection(client, collection_id)\n",
    "delete_provisioned_model_throughput(bedrock_client, provisioned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf9047-c8b1-4c1e-a6e9-6a89c5b874f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
